---
task: "1.2"
title: Requirement Review
course: TDT4242
group: 17
deadline: 2026-02-06T23:56:00
score: 4/5
status: submitted
attempt: 1
submitted: 2026-02-06T19:33:43
---

# Task 1.2 - Requirement Review

## Description

In this task, you will act as professional requirements reviewers, evaluating and improving software requirement specifications using IEEE SRS quality criteria (IEEE 830), including completeness, correctness, consistency, unambiguity, and verifiability.

You will receive a requirement document for the AIGuidebook system produced by another team and must manually review each requirement, identifying defects such as ambiguity, incompleteness, or inconsistency and providing precise, technically grounded feedback.

In parallel, your own requirement document from Task 1.1 will be reviewed by another team. You must carefully analyse their feedback and revise your original requirements, clearly explaining what was changed and why.

**Reference:** [IEEE 830 SRS Standard](https://seng.cankaya.edu.tr/wp-content/uploads/sites/53/2024/09/IEEE-SRS-830-1998.pdf)

## Expected Outcome

- **Attempt 1 - Review Report:** Identified defect types for each reviewed requirement (e.g., ambiguity, inconsistency).
- **Attempt 2 - Revised Requirement Document:** Updated requirements with clear justification for all changes.

## Evaluation Criteria

- Correct and consistent application of IEEE SRS quality criteria.
- Feedback is specific, actionable, and technically justified (not opinion-based).
- Revisions demonstrate thoughtful response to peer feedback, collaboration, and understanding of requirement quality.

## Our Submission

> Submitted: 2026-02-06 at 19:33:43
> Attached file: `Task 1.2-1770402822948-636202822.pdf`

### Review of Other Team's Requirements

**FR1:** As an institution, I want the system to provide assignment-level guidance on permitted and restricted AI use in clear, policy-aligned language so that students understand institutional academic integrity expectations without needing to interpret formal regulations.

- **Defect:** ambiguity, non-verifiability, incompleteness
- Terms such as "clear", "policy-aligned language", and "assignment-level guidance" are subjective and undefined. The requirement does not specify when the guidance is presented or what inputs it is based on, making it difficult to verify.
- **Suggestion:** As an institution, I want the system to display AI-use guidance based on the selected course and policy version, including an explicit list of permitted actions and prohibited actions, at assignment start and submission.

**FR2:** As a student, I want assignment-level guidance to clearly distinguish between acceptable supportive AI use and prohibited solution-generating use so that I can use AI responsibly without fear of accidental misconduct.

- **Defect:** ambiguity, non-verifiability, potential inconsistency
- The distinction between "supportive" and "solution-generating" AI use is not defined. The phrase "without fear of accidental misconduct" is not verifiable.
- **Suggestion:** As a student, I want assignment-level guidance to clearly distinguish between acceptable supportive AI use and prohibited solution-generating AI use by providing definitions and concrete examples, so that I can use AI responsibly and understand the boundaries of acceptable use.

**FR3:** As an institution, I want the system to support structured, student-controlled AI usage declarations per assignment, so that AI use can be transparently documented in alignment with academic integrity requirements.

- **Defect:** ambiguity, incompleteness, non-verifiability
- The requirement does not define what "structured" means, what information must be included, or how students control their declarations.
- **Suggestion:** As an institution, I want the system to support structured, student-controlled AI usage declarations per assignment, including predefined fields for tool type, usage category, and a brief description, so that AI use can be transparently and consistently documented in alignment with academic integrity requirements.

**FR4:** As an institution, I want AI usage declarations to be clearly separated from academic assessment processes, so that documentation supports integrity without automating evaluation or enforcement.

- **Defect:** ambiguity, non-verifiability
- The concept of "separation" is unclear, without explicit access or usage of constraints, the requirement cannot be verified.
- **Suggestion:** As an institution, I want AI usage declarations to be accessible independently from grading workflows and not used for automated assessment or enforcement decisions, so that documentation supports academic integrity without replacing human academic judgment.

**FR5:** As a student, I want to document AI use using high-level categories (e.g., explanation, structure, rephrasing, code assistance), so that documentation is accurate without requiring detailed prompt-by-prompt logging.

- **Assessment:** Seems good.

**FR6:** As a student, I want compliance feedback to be explanatory rather than judgmental, so that the system supports reflection and learning rather than academic judgment.

- **Defect:** ambiguity
- Terms such as "explanatory" and "judgmental" are subjective.
- **Suggestion:** As a student, I want compliance-related feedback to reference relevant policy clauses and provide explanatory guidance without using disciplinary or accusatory language, so that the system supports reflection and learning rather than replacing academic judgment.

**FR7:** As an institution, I want the system to support the versioning of institutional rules so that compliance checks and guidance can be traced to the correct policy context over time.

- **Assessment:** Seems good.

**FR8:** As an institution, I want the system to provide aggregated, student-facing dashboards of AI usage, so that AI documentation supports reflection and responsible study practices rather than surveillance.

- **Defect:** ambiguity
- The requirement does not define data types and sources.
- **Suggestion:** As an institution, I want the system to provide aggregated, student-facing dashboards of AI usage, monitoring history prompt usage and AI answer acceptance, so that AI documentation supports reflection and responsible study practices rather than surveillance.

**FR9:** As a student, I want AI usage data to be private by default and visible primarily to me, so that I feel safe documenting my AI use honestly.

- **Defect:** ambiguity, consistency
- Phrases such as "private by default" and "primarily to me" are vague and potentially inconsistent with FR10.
- **Suggestion:** As a student, I want my AI usage data to be private by default and visible only to me unless I explicitly choose to share it, so that I feel safe documenting my AI use honestly.

**FR10:** As a student, I want to control when and with whom my AI usage data is shared, so that I remain confident that the system is not used for unintended monitoring.

- **Defect:** incompleteness, consistency
- The requirement does not specify who data can be shared with, how sharing is controlled, or whether access can be revoked.
- **Suggestion:** As a student, I want to control when and with whom my AI usage data is shared on a per-assignment basis, and to be able to revoke that access, so that I remain confident the system is not used for unintended monitoring.

**NFR1 (Privacy):** As an institution, I want the system to collect and store only the AI usage data required for educational guidance and integrity documentation, so that student privacy is preserved.

- **Defect:** ambiguity
- Concept such as "only required data" is vague.
- **Suggestion:** As an institution, I want the system to collect and store only a clearly defined minimal set of AI usage data necessary for educational guidance and integrity documentation, so that student privacy is preserved.

**NFR2 (Access Control):** As an institution, I want AI usage data to be protected by strict role-based access controls, so that data is accessed only for explicitly authorized educational purposes.

- **Assessment:** Seems good.

**NFR3 (Student Trust):** As a student, I want assurance that my AI usage data will not be reused for disciplinary or evaluative purposes beyond its stated scope, so that I feel safe using the system honestly.

- **Defect:** ambiguity
- Term such as "assurance" is vague.
- **Suggestion:** As a student, I want the system to clearly explain how my AI usage data is used and to technically restrict its use to that stated scope, so that I feel safe using the system honestly.

**NFR4 (Ethical Scope):** As an institution, I want the system to require human review before any plagiarism accusations or disciplinary decisions are made, so that ethical boundaries between guidance and academic judgment are maintained.

- **Assessment:** Seems good.

**NFR5 (Non-Surveillance):** As a student, I want the system to avoid hidden tracking or behavioral profiling, so that my use of the system is not treated as surveillance or policing.

- **Assessment:** Seems good.

**NFR6 (Usability):** As a student, I want AI usage documentation to be completed using a small number of structured inputs per assignment, so that documenting AI use does not add significant overhead during assignment work.

- **Defect:** ambiguity
- Terms such as "small number", "significant overhead" should be avoided.
- **Suggestion:** As a student, I want AI usage documentation requires no more than 5 structured fields and should be completable within 15 minutes, so that documenting AI use does not add significant overhead during assignment work.

**NFR7 (Clarity):** System-generated guidance and feedback shall avoid evaluative or disciplinary language and instead provide explanatory, policy-aligned information to students.

- **Assessment:** Seems good.

**NFR8 (Transparency):** As an institution, I want the system to clearly communicate what AI usage data is collected, why it is collected, and how it is used, so that trust and legitimacy are maintained.

- **Assessment:** Seems good.

**NFR9 (Explainability):** As a student, I want system feedback and guidance to be understandable and well-explained, so that I can make informed decisions about my AI use.

- **Assessment:** Seems good.

**NFR10 (Adaptability):** As an institution, I want the system to support updates to policies and supported AI tools without fundamental redesign, so that it remains aligned with evolving regulations and educational practices.

- **Defect:** ambiguity
- Term such as "without fundamental redesign" is vague.
- **Suggestion:** As an institution, I want to be able to update policy rules and the supported AI tool list via a configuration interface without requiring application redeployment, so that it remains aligned with evolving regulations and educational practices.

## Feedback

> **Score: 4/5**

Overall is good. But you can also detect the "standard" non-functional attributes of a system and align the NFRs to i.e. ISO quality model.
